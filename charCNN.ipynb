{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "charCNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOUIoFGMBDZKyu0TeBamxEO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/0Park/Deeplearning-NLP/blob/master/charCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "av9kjHR-Psl2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import urllib.request\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nExqS2lhP7cA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "urllib.request.urlretrieve(\"http://www.gutenberg.org/files/11/11-0.txt\", filename=\"11-0.txt\")\n",
        "f=open('11-0.txt','rb')\n",
        "lines=[]\n",
        "for line in f:\n",
        "  line=line.strip()  # remove \\r, \\n\n",
        "  line=line.lower()\n",
        "  line=line.decode('ascii','ignore')\n",
        "  if len(line) >0:\n",
        "    lines.append(line)\n",
        "f.close()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ok2LnZvsQxFg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "a9e77bd7-bdfc-455a-e49f-5377545bb720"
      },
      "source": [
        "lines[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the project gutenberg ebook of alices adventures in wonderland, by lewis carroll',\n",
              " 'this ebook is for the use of anyone anywhere at no cost and with',\n",
              " 'almost no restrictions whatsoever.  you may copy it, give it away or',\n",
              " 're-use it under the terms of the project gutenberg license included',\n",
              " 'with this ebook or online at www.gutenberg.org']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVQNA9WfQ0Rm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "085bd7a1-fa33-4958-9522-3212c829cbab"
      },
      "source": [
        "text=' '.join(lines)\n",
        "print('문자열의 길이 또는 총 글자의 개수 %d' %len(text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "문자열의 길이 또는 총 글자의 개수 159612\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ycRc3efRC6v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "107b5b1a-ae46-43cc-987e-9c98bc0fbbcc"
      },
      "source": [
        "print(text[:200])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the project gutenberg ebook of alices adventures in wonderland, by lewis carroll this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever.  you may copy it, g\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2h5ROJXRFX_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e55a724c-196f-4bcd-e539-43c0da28b0b5"
      },
      "source": [
        "char_vocab=sorted(list(set(text))) # remove repetition\n",
        "vocab_size=len(char_vocab)\n",
        "print('글자 집합의 크기: {}'.format(vocab_size))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "글자 집합의 크기: 57\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tm8hTVylRiPv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "699c407b-20f7-45d3-8e76-960013642ffe"
      },
      "source": [
        "char_to_index=dict((c,i) for i,c in enumerate(char_vocab))\n",
        "print(char_to_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{' ': 0, '!': 1, '\"': 2, '#': 3, '$': 4, '%': 5, \"'\": 6, '(': 7, ')': 8, '*': 9, ',': 10, '-': 11, '.': 12, '/': 13, '0': 14, '1': 15, '2': 16, '3': 17, '4': 18, '5': 19, '6': 20, '7': 21, '8': 22, '9': 23, ':': 24, ';': 25, '?': 26, '@': 27, '[': 28, ']': 29, '_': 30, 'a': 31, 'b': 32, 'c': 33, 'd': 34, 'e': 35, 'f': 36, 'g': 37, 'h': 38, 'i': 39, 'j': 40, 'k': 41, 'l': 42, 'm': 43, 'n': 44, 'o': 45, 'p': 46, 'q': 47, 'r': 48, 's': 49, 't': 50, 'u': 51, 'v': 52, 'w': 53, 'x': 54, 'y': 55, 'z': 56}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmKp2x05R04-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index_to_char={}\n",
        "for key,value in char_to_index.items():\n",
        "  index_to_char[value]=key"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZK8zWF892egB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c570a3d3-a065-484d-9236-33860b77b3c8"
      },
      "source": [
        "seq_length=60 # length of sentence\n",
        "n_samples=int(np.floor((len(text)-1)/seq_length))\n",
        "print('문장 샘플의 수:{}'.format(n_samples))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "문장 샘플의 수:2660\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xCe_ewP25nv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_X=[]\n",
        "train_y=[]\n",
        "\n",
        "for i in range(n_samples):\n",
        "  X_samples=text[i*seq_length:(i+1)*seq_length]\n",
        "  X_encoded=[char_to_index[c] for c in X_samples]\n",
        "  train_X.append(X_encoded)\n",
        "\n",
        "  y_sample=text[i*seq_length+1:(i+1)*seq_length+1]\n",
        "  y_encoded=[char_to_index[c] for c in y_sample]\n",
        "  train_y.append(y_encoded)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wgik8oX23jy3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# No embedding, one hot encoding\n",
        "train_X=to_categorical(train_X)\n",
        "train_y=to_categorical(train_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsCFwQuA3uuO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e063f387-24df-4344-8f2e-6bba408c1dc9"
      },
      "source": [
        "print('train_X의 크기(shape):{}'.format(train_X.shape))\n",
        "print('train_y의 크기(shape):{}'.format(train_y.shape))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_X의 크기(shape):(2660, 60, 57)\n",
            "train_y의 크기(shape):(2660, 60, 57)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3u7MKmq3-Y9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,LSTM,TimeDistributed\n",
        "\n",
        "model=Sequential()\n",
        "model.add(LSTM(256,input_shape=(None,train_X.shape[2]),return_sequences=True))\n",
        "model.add(LSTM(256,return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(vocab_size,activation='softmax')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuY68oqj4y0X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "acda3c2b-a36b-4589-c5a2-042406db0ee7"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.fit(train_X,train_y,epochs=80,verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "84/84 - 48s - loss: 3.0686 - accuracy: 0.1840\n",
            "Epoch 2/80\n",
            "84/84 - 48s - loss: 2.8007 - accuracy: 0.2288\n",
            "Epoch 3/80\n",
            "84/84 - 49s - loss: 2.4728 - accuracy: 0.3107\n",
            "Epoch 4/80\n",
            "84/84 - 48s - loss: 2.3331 - accuracy: 0.3401\n",
            "Epoch 5/80\n",
            "84/84 - 49s - loss: 2.2475 - accuracy: 0.3589\n",
            "Epoch 6/80\n",
            "84/84 - 48s - loss: 2.1753 - accuracy: 0.3783\n",
            "Epoch 7/80\n",
            "84/84 - 48s - loss: 2.1160 - accuracy: 0.3937\n",
            "Epoch 8/80\n",
            "84/84 - 48s - loss: 2.0686 - accuracy: 0.4060\n",
            "Epoch 9/80\n",
            "84/84 - 49s - loss: 2.0293 - accuracy: 0.4157\n",
            "Epoch 10/80\n",
            "84/84 - 49s - loss: 1.9931 - accuracy: 0.4248\n",
            "Epoch 11/80\n",
            "84/84 - 49s - loss: 1.9563 - accuracy: 0.4333\n",
            "Epoch 12/80\n",
            "84/84 - 49s - loss: 1.9261 - accuracy: 0.4418\n",
            "Epoch 13/80\n",
            "84/84 - 50s - loss: 1.8959 - accuracy: 0.4494\n",
            "Epoch 14/80\n",
            "84/84 - 48s - loss: 1.8688 - accuracy: 0.4568\n",
            "Epoch 15/80\n",
            "84/84 - 48s - loss: 1.8402 - accuracy: 0.4650\n",
            "Epoch 16/80\n",
            "84/84 - 48s - loss: 1.8157 - accuracy: 0.4711\n",
            "Epoch 17/80\n",
            "84/84 - 49s - loss: 1.7913 - accuracy: 0.4785\n",
            "Epoch 18/80\n",
            "84/84 - 48s - loss: 1.7657 - accuracy: 0.4854\n",
            "Epoch 19/80\n",
            "84/84 - 48s - loss: 1.7449 - accuracy: 0.4910\n",
            "Epoch 20/80\n",
            "84/84 - 50s - loss: 1.7231 - accuracy: 0.4963\n",
            "Epoch 21/80\n",
            "84/84 - 50s - loss: 1.6991 - accuracy: 0.5031\n",
            "Epoch 22/80\n",
            "84/84 - 51s - loss: 1.6786 - accuracy: 0.5084\n",
            "Epoch 23/80\n",
            "84/84 - 50s - loss: 1.6599 - accuracy: 0.5134\n",
            "Epoch 24/80\n",
            "84/84 - 50s - loss: 1.6372 - accuracy: 0.5191\n",
            "Epoch 25/80\n",
            "84/84 - 48s - loss: 1.6170 - accuracy: 0.5248\n",
            "Epoch 26/80\n",
            "84/84 - 48s - loss: 1.6014 - accuracy: 0.5288\n",
            "Epoch 27/80\n",
            "84/84 - 48s - loss: 1.5809 - accuracy: 0.5353\n",
            "Epoch 28/80\n",
            "84/84 - 48s - loss: 1.5643 - accuracy: 0.5387\n",
            "Epoch 29/80\n",
            "84/84 - 48s - loss: 1.5445 - accuracy: 0.5446\n",
            "Epoch 30/80\n",
            "84/84 - 49s - loss: 1.5293 - accuracy: 0.5489\n",
            "Epoch 31/80\n",
            "84/84 - 49s - loss: 1.5097 - accuracy: 0.5543\n",
            "Epoch 32/80\n",
            "84/84 - 49s - loss: 1.4949 - accuracy: 0.5579\n",
            "Epoch 33/80\n",
            "84/84 - 49s - loss: 1.4790 - accuracy: 0.5633\n",
            "Epoch 34/80\n",
            "84/84 - 48s - loss: 1.4618 - accuracy: 0.5671\n",
            "Epoch 35/80\n",
            "84/84 - 48s - loss: 1.4452 - accuracy: 0.5712\n",
            "Epoch 36/80\n",
            "84/84 - 48s - loss: 1.4301 - accuracy: 0.5751\n",
            "Epoch 37/80\n",
            "84/84 - 48s - loss: 1.4152 - accuracy: 0.5791\n",
            "Epoch 38/80\n",
            "84/84 - 48s - loss: 1.3989 - accuracy: 0.5837\n",
            "Epoch 39/80\n",
            "84/84 - 48s - loss: 1.3875 - accuracy: 0.5864\n",
            "Epoch 40/80\n",
            "84/84 - 49s - loss: 1.3693 - accuracy: 0.5912\n",
            "Epoch 41/80\n",
            "84/84 - 49s - loss: 1.3579 - accuracy: 0.5953\n",
            "Epoch 42/80\n",
            "84/84 - 49s - loss: 1.3405 - accuracy: 0.6001\n",
            "Epoch 43/80\n",
            "84/84 - 49s - loss: 1.3262 - accuracy: 0.6034\n",
            "Epoch 44/80\n",
            "84/84 - 49s - loss: 1.3115 - accuracy: 0.6078\n",
            "Epoch 45/80\n",
            "84/84 - 50s - loss: 1.2987 - accuracy: 0.6112\n",
            "Epoch 46/80\n",
            "84/84 - 49s - loss: 1.2838 - accuracy: 0.6157\n",
            "Epoch 47/80\n",
            "84/84 - 48s - loss: 1.2708 - accuracy: 0.6188\n",
            "Epoch 48/80\n",
            "84/84 - 48s - loss: 1.2566 - accuracy: 0.6231\n",
            "Epoch 49/80\n",
            "84/84 - 48s - loss: 1.2421 - accuracy: 0.6268\n",
            "Epoch 50/80\n",
            "84/84 - 48s - loss: 1.2282 - accuracy: 0.6315\n",
            "Epoch 51/80\n",
            "84/84 - 48s - loss: 1.2150 - accuracy: 0.6347\n",
            "Epoch 52/80\n",
            "84/84 - 50s - loss: 1.2006 - accuracy: 0.6391\n",
            "Epoch 53/80\n",
            "84/84 - 50s - loss: 1.1874 - accuracy: 0.6422\n",
            "Epoch 54/80\n",
            "84/84 - 50s - loss: 1.1729 - accuracy: 0.6467\n",
            "Epoch 55/80\n",
            "84/84 - 48s - loss: 1.1570 - accuracy: 0.6517\n",
            "Epoch 56/80\n",
            "84/84 - 48s - loss: 1.1441 - accuracy: 0.6553\n",
            "Epoch 57/80\n",
            "84/84 - 48s - loss: 1.1306 - accuracy: 0.6597\n",
            "Epoch 58/80\n",
            "84/84 - 48s - loss: 1.1165 - accuracy: 0.6627\n",
            "Epoch 59/80\n",
            "84/84 - 48s - loss: 1.1034 - accuracy: 0.6661\n",
            "Epoch 60/80\n",
            "84/84 - 48s - loss: 1.0888 - accuracy: 0.6703\n",
            "Epoch 61/80\n",
            "84/84 - 49s - loss: 1.0743 - accuracy: 0.6748\n",
            "Epoch 62/80\n",
            "84/84 - 48s - loss: 1.0582 - accuracy: 0.6803\n",
            "Epoch 63/80\n",
            "84/84 - 49s - loss: 1.0439 - accuracy: 0.6845\n",
            "Epoch 64/80\n",
            "84/84 - 51s - loss: 1.0270 - accuracy: 0.6898\n",
            "Epoch 65/80\n",
            "84/84 - 48s - loss: 1.0123 - accuracy: 0.6939\n",
            "Epoch 66/80\n",
            "84/84 - 48s - loss: 1.0025 - accuracy: 0.6971\n",
            "Epoch 67/80\n",
            "84/84 - 49s - loss: 0.9829 - accuracy: 0.7026\n",
            "Epoch 68/80\n",
            "84/84 - 49s - loss: 0.9711 - accuracy: 0.7067\n",
            "Epoch 69/80\n",
            "84/84 - 49s - loss: 0.9542 - accuracy: 0.7119\n",
            "Epoch 70/80\n",
            "84/84 - 49s - loss: 0.9387 - accuracy: 0.7158\n",
            "Epoch 71/80\n",
            "84/84 - 49s - loss: 0.9260 - accuracy: 0.7207\n",
            "Epoch 72/80\n",
            "84/84 - 49s - loss: 0.9096 - accuracy: 0.7249\n",
            "Epoch 73/80\n",
            "84/84 - 48s - loss: 0.8925 - accuracy: 0.7310\n",
            "Epoch 74/80\n",
            "84/84 - 48s - loss: 0.8783 - accuracy: 0.7351\n",
            "Epoch 75/80\n",
            "84/84 - 49s - loss: 0.8622 - accuracy: 0.7407\n",
            "Epoch 76/80\n",
            "84/84 - 53s - loss: 0.8459 - accuracy: 0.7459\n",
            "Epoch 77/80\n",
            "84/84 - 48s - loss: 0.8304 - accuracy: 0.7506\n",
            "Epoch 78/80\n",
            "84/84 - 49s - loss: 0.8138 - accuracy: 0.7561\n",
            "Epoch 79/80\n",
            "84/84 - 49s - loss: 0.8035 - accuracy: 0.7601\n",
            "Epoch 80/80\n",
            "84/84 - 49s - loss: 0.7890 - accuracy: 0.7635\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7d2e91e5c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwbriBZ98T2-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}